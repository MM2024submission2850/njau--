{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入要爬取的关键字:AOMO澳墨土壤修复\n",
      "一共有1个公众号\n"
     ]
    }
   ],
   "source": [
    "#获取微信公众号，进行整站爬取\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import random\n",
    "from pyquery import PyQuery\n",
    "from requests import RequestException\n",
    "import csv\n",
    "\n",
    "wechat_url = \"https://mp.weixin.qq.com/\"  #公众号主页\n",
    "account = \"1328436416@qq.com\"             #请使用自己的微信公众号登录账户\n",
    "password = \"243698cyc\"          #请使用自己的微信公众号登录密码\n",
    "wechat_official_url = \"https://mp.weixin.qq.com/cgi-bin/searchbiz?\"  #公众号搜索页面，获取公众号列表\n",
    "header = {\n",
    "    \"Host\": \"mp.weixin.qq.com\",\n",
    "    \"User - Agent\": \"Mozilla / 5.0(WindowsNT10.0;WOW64) AppleWebKit / 537.36(KHTML, likeGecko) Chrome / 71.0.3578.98Safari / 537.36\"\n",
    "}\n",
    "article_url = \"https://mp.weixin.qq.com/cgi-bin/appmsg?\"     #文章页面，获取文章列表\n",
    "data_count = 1\n",
    "ip_pool=list()\n",
    "proxy_ip=None\n",
    "\n",
    "#读取代理IP,获得所有Ip\n",
    "def get_ip_pool():\n",
    "    with open(\"proxy_ip.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "        content = f.readlines()\n",
    "    for i in range(len(content)):\n",
    "        content[i] = content[i].rstrip(\"\\n\").replace('\\\"', \"\")\n",
    "        ip_pool.append(content[i])\n",
    "\n",
    "#获取代理Ip\n",
    "def get_proxy_ip():\n",
    "    global proxy_ip\n",
    "    proxy_ip = ip_pool[random.randint(0,len(ip_pool)-1)]\n",
    "\n",
    "\n",
    "#打开微信公众号主页面,登录微信公众号\n",
    "#获取cookie信息\n",
    "def open_wechat_official():\n",
    "    browser = webdriver.Chrome()\n",
    "    wait = WebDriverWait(browser, 2)\n",
    "    try:\n",
    "        post = {}\n",
    "        browser.get(wechat_url)\n",
    "        \n",
    "        time.sleep(15)  #等待用户手机扫码登录\n",
    "        #将cookies写入文件，进行保存，长期使用\n",
    "        cookies_items = browser.get_cookies()\n",
    "        # print(cookies_items)\n",
    "        for cookie_item in cookies_items:\n",
    "            post [cookie_item[\"name\"]] = cookie_item[\"value\"]\n",
    "        cookie_str = json.dumps(post)\n",
    "        with open(\"cookie.txt\",\"w+\",encoding=\"utf-8\") as f:\n",
    "            f.write(cookie_str)\n",
    "    except TimeoutException:\n",
    "        open_wechat_official()\n",
    "\n",
    "\n",
    "#开始微信公众号的爬取\n",
    "# 获取token和cookie\n",
    "def get_token_and_cookie():\n",
    "    with open (\"cookie.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "        cookie = f.read()\n",
    "    cookies = json.loads(cookie)\n",
    "    response = requests.get(url = wechat_url,headers=header,cookies=cookies)\n",
    "    # print(response.url)\n",
    "    pattern = re.compile(\"token=(\\d+)\",re.S)\n",
    "    token = re.search(pattern,str(response.url))[1]\n",
    "    # print(token)\n",
    "    return cookies,token\n",
    "\n",
    "#进入微信公众号的接口处，输入关键字\n",
    "#获取fakeid\n",
    "def get_wechat_fakeid(cookies,token,keyword):\n",
    "    query_id = {\n",
    "        \"action\" :\"search_biz\",\n",
    "        \"token\" :token,\n",
    "        \"lang\" : \"zh_CN\",\n",
    "        \"f\" : \"json\",\n",
    "        \"ajax\" : 1,\n",
    "        \"random\" : random.random(),\n",
    "        \"query\" : keyword,\n",
    "        \"begin\" : \"0\",   #控制页数\n",
    "        \"count\" :\"5\"\n",
    "    }\n",
    "    search_response = requests.get(wechat_official_url,cookies=cookies,headers=header,params=query_id)\n",
    "    total_offical = search_response.json().get(\"total\")\n",
    "    # print(total_offical) #总的公众号个数，每页5个，自行处理\n",
    "    #获取搜索到的所以微信公众号\n",
    "    print(\"一共有%d个公众号\" % total_offical)\n",
    "    for num in range(0,int(total_offical)//5):\n",
    "        print(\"第%d页公众号\" % num)\n",
    "        begin = num*5\n",
    "        query_id = {\n",
    "            \"action\" :\"search_biz\",\n",
    "            \"token\" :token,\n",
    "            \"lang\" : \"zh_CN\",\n",
    "            \"f\" : \"json\",\n",
    "            \"ajax\" : 1,\n",
    "            \"random\" : random.random(),\n",
    "            \"query\" : keyword,\n",
    "            \"begin\" : str(begin),   #控制页数\n",
    "            \"count\" :\"5\"\n",
    "        }\n",
    "        search_response = requests.get(wechat_official_url,cookies=cookies,headers=header,params=query_id)\n",
    "        for wechat_list in search_response.json().get(\"list\"):\n",
    "            # print(wechat_list)\n",
    "            fakeid = wechat_list.get(\"fakeid\")\n",
    "            nickname = wechat_list.get(\"nickname\")  #微信名\n",
    "            alias = wechat_list.get(\"alias\")    #微信号\n",
    "            print(\"公众号的名字是：%s \" % nickname)\n",
    "            yield {\n",
    "                \"fakeid\" : fakeid,\n",
    "                \"nickname\" : nickname,\n",
    "                \"alias\" : alias\n",
    "            }\n",
    "        print(\"公众号翻页中。。。\")\n",
    "        time.sleep(2)\n",
    "\n",
    "#进入具体的公众号，获取文章列表\n",
    "def input_wechat_get_article(cookies,token,fakeid):\n",
    "    query_id ={\n",
    "        \"token\" :token,\n",
    "        \"lang\" : \"zh_CN\",\n",
    "        \"f\" : \"json\",\n",
    "        \"ajax\" : 1,\n",
    "        \"random\" :random.random(),\n",
    "        \"action\" :\"list_ex\",\n",
    "        \"begin\" : 0,  #控制页数\n",
    "        \"count\" : 5,\n",
    "        \"query\" :\"\",\n",
    "        \"fakeid\" :fakeid,\n",
    "        \"type\":9\n",
    "    }\n",
    "    appmsg_response = requests.get(article_url,cookies=cookies,headers=header,params=query_id)\n",
    "    total_article = appmsg_response.json().get(\"app_msg_cnt\") #总文章数，每页五个，自行处理\n",
    "    if total_article:\n",
    "        print(\"该公众号共有%d个数据\" % total_article)\n",
    "        #获取所有文章\n",
    "        total_page = int(total_article)//5\n",
    "        if total_page == 0 :\n",
    "            total_page +=1\n",
    "        for num in range(total_page):\n",
    "            if num > 20 :\n",
    "                break\n",
    "            print(\"该公众号的第%d页数据\" % num)\n",
    "            begin = num*5\n",
    "            query_id ={\n",
    "                \"token\" :token,\n",
    "                \"lang\" : \"zh_CN\",\n",
    "                \"f\" : \"json\",\n",
    "                \"ajax\" : 1,\n",
    "                \"random\" :random.random(),\n",
    "                \"action\" :\"list_ex\",\n",
    "                \"begin\" : str(begin),  #控制页数\n",
    "                \"count\" : 5,\n",
    "                \"query\" :\"\",\n",
    "                \"fakeid\" :fakeid,\n",
    "                \"type\":9\n",
    "            }#cookies=cookies,\n",
    "            appmsg_response = requests.get(article_url,cookies=cookies, headers=header, params=query_id)\n",
    "            if appmsg_response.json().get(\"base_resp\").get(\"err_msg\") == \"ok\":\n",
    "                for article in appmsg_response.json().get(\"app_msg_list\"):\n",
    "                    article_link_url = article.get(\"link\")\n",
    "                    article_title = article.get(\"title\")\n",
    "                    article_time = article.get(\"update_time\")\n",
    "                    yield {\n",
    "                        \"article_link_url\" : article_link_url,\n",
    "                        \"article_title\" : article_title,\n",
    "                        \"article_time\" : article_time\n",
    "                    }\n",
    "                print(\"文章翻页中.....\")\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                time.sleep(4000)\n",
    "\n",
    "#获取文章的html代码\n",
    "def get_article_html(url):\n",
    "    try:\n",
    "        response = requests.get(url,headers=header)\n",
    "        if response.status_code == 200 :\n",
    "            return response.text\n",
    "        else:\n",
    "            return None\n",
    "    except RequestException:\n",
    "        return None\n",
    "\n",
    "#获取文章内容\n",
    "def parse_article_content(html):\n",
    "    doc = PyQuery(html)\n",
    "    content = doc(\".rich_media_content p\").text()\n",
    "    content = content.replace(\"\\r\\n\", \"\")\n",
    "    content = content.replace(\"\\n\", \"\")\n",
    "    return content\n",
    "\n",
    "\n",
    "#写入文件txt格式\n",
    "def save_to_file(content):\n",
    "    with open(\"wechat_official.txt\",\"a+\",encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(content, ensure_ascii=False) + \"\\n\")\n",
    "        f.close()\n",
    "\n",
    "\n",
    "#写入文件标题\n",
    "def write_title_file():\n",
    "    with open (\"wechat_official.csv\",\"a+\",encoding=\"utf-8-sig\",newline=\"\") as f:\n",
    "        wea_for=csv.writer(f,delimiter=\",\")\n",
    "        wea_for.writerow([\"微信名\",\"微信号\",\"标题\",\"时间\",\"内容\"])\n",
    "\n",
    "#写入文件内容\n",
    "def write_content_file(content):\n",
    "    with open (\"wechat_official.csv\",\"a+\",encoding=\"utf-8-sig\",newline=\"\") as f:\n",
    "        wea_for=csv.writer(f,delimiter=\",\")\n",
    "        wea_for.writerow([content[\"nickname\"],content[\"alias\"],content[\"title\"],content[\"date\"],content[\"content\"]])\n",
    "\n",
    "#主函数\n",
    "def main():\n",
    "    global data_count\n",
    "    open_wechat_official()   #获取cookies，一般不用每次都运行，每天运行一次\n",
    "    write_title_file()\n",
    "    cookies,token = get_token_and_cookie()\n",
    "    keyword = input(\"请输入要爬取的关键字:\")\n",
    "    for wechat_official in get_wechat_fakeid(cookies,token,keyword):\n",
    "        # print(wechat_official)\n",
    "        fakeid = wechat_official[\"fakeid\"]\n",
    "        nickname = wechat_official[\"nickname\"]\n",
    "        alias = wechat_official[\"alias\"]\n",
    "        for wechat_article in input_wechat_get_article(cookies,token,fakeid):\n",
    "            # print(wechat_article)\n",
    "            article_link_url = wechat_article[\"article_link_url\"]\n",
    "            article_title = wechat_article[\"article_title\"]\n",
    "            article_time = wechat_article[\"article_time\"]\n",
    "            date = time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(article_time))\n",
    "            html = get_article_html(article_link_url)\n",
    "            if html :\n",
    "                content = parse_article_content(html)\n",
    "                crawl_content = {\n",
    "                    \"nickname\" : nickname, #微信名\n",
    "                    \"alias\" : alias,   #微信号\n",
    "                    \"title\" : article_title,\n",
    "                    \"date\" : date, #时间\n",
    "                    \"content\" : content #内容\n",
    "                }\n",
    "                write_content_file(crawl_content)\n",
    "                # save_to_file(crawl_content)\n",
    "                print(\"获取到第%d条数据\" % data_count)\n",
    "                data_count +=1\n",
    "                # print(crawl_content)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入要爬取的关键字:土壤修复\n",
      "一共有10个公众号\n"
     ]
    }
   ],
   "source": [
    "#获取微信公众号，进行整站爬取\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import random\n",
    "from pyquery import PyQuery\n",
    "from requests import RequestException\n",
    "import csv\n",
    "\n",
    "wechat_url = \"https://mp.weixin.qq.com/\"  #公众号主页\n",
    "account = \"1328436416@qq.com\"             #请使用自己的微信公众号登录账户\n",
    "password = \"243698cyc\"          #请使用自己的微信公众号登录密码\n",
    "wechat_official_url = \"https://mp.weixin.qq.com/cgi-bin/searchbiz?\"  #公众号搜索页面，获取公众号列表\n",
    "header = {\n",
    "    \"Host\": \"mp.weixin.qq.com\",\n",
    "    \"User - Agent\": \"Mozilla / 5.0(WindowsNT10.0;WOW64) AppleWebKit / 537.36(KHTML, likeGecko) Chrome / 71.0.3578.98Safari / 537.36\"\n",
    "}\n",
    "article_url = \"https://mp.weixin.qq.com/cgi-bin/appmsg?\"     #文章页面，获取文章列表\n",
    "data_count = 1\n",
    "ip_pool=list()\n",
    "proxy_ip=None\n",
    "\n",
    "#读取代理IP,获得所有Ip\n",
    "def get_ip_pool():\n",
    "    with open(\"proxy_ip.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "        content = f.readlines()\n",
    "    for i in range(len(content)):\n",
    "        content[i] = content[i].rstrip(\"\\n\").replace('\\\"', \"\")\n",
    "        ip_pool.append(content[i])\n",
    "\n",
    "#获取代理Ip\n",
    "def get_proxy_ip():\n",
    "    global proxy_ip\n",
    "    proxy_ip = ip_pool[random.randint(0,len(ip_pool)-1)]\n",
    "\n",
    "\n",
    "#打开微信公众号主页面,登录微信公众号\n",
    "#获取cookie信息\n",
    "def open_wechat_official():\n",
    "    browser = webdriver.Chrome()\n",
    "    wait = WebDriverWait(browser, 2)\n",
    "    try:\n",
    "        post = {}\n",
    "        browser.get(wechat_url)\n",
    "        \n",
    "        time.sleep(15)  #等待用户手机扫码登录\n",
    "        #将cookies写入文件，进行保存，长期使用\n",
    "        cookies_items = browser.get_cookies()\n",
    "        # print(cookies_items)\n",
    "        for cookie_item in cookies_items:\n",
    "            post [cookie_item[\"name\"]] = cookie_item[\"value\"]\n",
    "        cookie_str = json.dumps(post)\n",
    "        with open(\"cookie.txt\",\"w+\",encoding=\"utf-8\") as f:\n",
    "            f.write(cookie_str)\n",
    "    except TimeoutException:\n",
    "        open_wechat_official()\n",
    "\n",
    "\n",
    "#开始微信公众号的爬取\n",
    "# 获取token和cookie\n",
    "def get_token_and_cookie():\n",
    "    with open (\"cookie.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "        cookie = f.read()\n",
    "    cookies = json.loads(cookie)\n",
    "    response = requests.get(url = wechat_url,headers=header,cookies=cookies)\n",
    "    # print(response.url)\n",
    "    pattern = re.compile(\"token=(\\d+)\",re.S)\n",
    "    token = re.search(pattern,str(response.url))[1]\n",
    "    # print(token)\n",
    "    return cookies,token\n",
    "\n",
    "#进入微信公众号的接口处，输入关键字\n",
    "#获取fakeid\n",
    "def get_wechat_fakeid(cookies,token,keyword):\n",
    "    query_id = {\n",
    "        \"action\" :\"search_biz\",\n",
    "        \"token\" :token,\n",
    "        \"lang\" : \"zh_CN\",\n",
    "        \"f\" : \"json\",\n",
    "        \"ajax\" : 1,\n",
    "        \"random\" : random.random(),\n",
    "        \"query\" : keyword,\n",
    "        \"begin\" : \"0\",   #控制页数\n",
    "        \"count\" :\"20\"\n",
    "    }\n",
    "    search_response = requests.get(wechat_official_url,cookies=cookies,headers=header,params=query_id)\n",
    "    total_offical = search_response.json().get(\"total\")\n",
    "    # print(total_offical) #总的公众号个数，每页5个，自行处理\n",
    "    #获取搜索到的所以微信公众号\n",
    "    print(\"一共有%d个公众号\" % total_offical)\n",
    "    for num in range(0,int(total_offical)//20):\n",
    "        print(\"第%d页公众号\" % num)\n",
    "        begin = num*5\n",
    "        query_id = {\n",
    "            \"action\" :\"search_biz\",\n",
    "            \"token\" :token,\n",
    "            \"lang\" : \"zh_CN\",\n",
    "            \"f\" : \"json\",\n",
    "            \"ajax\" : 1,\n",
    "            \"random\" : random.random(),\n",
    "            \"query\" : keyword,\n",
    "            \"begin\" : str(begin),   #控制页数\n",
    "            \"count\" :\"20\"\n",
    "        }\n",
    "        search_response = requests.get(wechat_official_url,cookies=cookies,headers=header,params=query_id)\n",
    "        for wechat_list in search_response.json().get(\"list\"):\n",
    "            # print(wechat_list)\n",
    "            fakeid = wechat_list.get(\"fakeid\")\n",
    "            nickname = wechat_list.get(\"nickname\")  #微信名\n",
    "            alias = wechat_list.get(\"alias\")    #微信号\n",
    "            print(\"公众号的名字是：%s \" % nickname)\n",
    "            yield {\n",
    "                \"fakeid\" : fakeid,\n",
    "                \"nickname\" : nickname,\n",
    "                \"alias\" : alias\n",
    "            }\n",
    "        print(\"公众号翻页中。。。\")\n",
    "        time.sleep(2)\n",
    "\n",
    "#进入具体的公众号，获取文章列表\n",
    "def input_wechat_get_article(cookies,token,fakeid):\n",
    "    query_id ={\n",
    "        \"token\" :token,\n",
    "        \"lang\" : \"zh_CN\",\n",
    "        \"f\" : \"json\",\n",
    "        \"ajax\" : 1,\n",
    "        \"random\" :random.random(),\n",
    "        \"action\" :\"list_ex\",\n",
    "        \"begin\" : 0,  #控制页数\n",
    "        \"count\" : 20,\n",
    "        \"query\" :\"\",\n",
    "        \"fakeid\" :fakeid,\n",
    "        \"type\":9\n",
    "    }\n",
    "    appmsg_response = requests.get(article_url,cookies=cookies,headers=header,params=query_id)\n",
    "    total_article = appmsg_response.json().get(\"app_msg_cnt\") #总文章数，每页五个，自行处理\n",
    "    if total_article:\n",
    "        print(\"该公众号共有%d个数据\" % total_article)\n",
    "        #获取所有文章\n",
    "        total_page = int(total_article)//5\n",
    "        if total_page == 0 :\n",
    "            total_page +=1\n",
    "        for num in range(total_page):\n",
    "            if num > 20 :\n",
    "                break\n",
    "            print(\"该公众号的第%d页数据\" % num)\n",
    "            begin = num*20\n",
    "            query_id ={\n",
    "                \"token\" :token,\n",
    "                \"lang\" : \"zh_CN\",\n",
    "                \"f\" : \"json\",\n",
    "                \"ajax\" : 1,\n",
    "                \"random\" :random.random(),\n",
    "                \"action\" :\"list_ex\",\n",
    "                \"begin\" : str(begin),  #控制页数\n",
    "                \"count\" : 20,\n",
    "                \"query\" :\"\",\n",
    "                \"fakeid\" :fakeid,\n",
    "                \"type\":9\n",
    "            }#cookies=cookies,\n",
    "            appmsg_response = requests.get(article_url,cookies=cookies, headers=header, params=query_id)\n",
    "            if appmsg_response.json().get(\"base_resp\").get(\"err_msg\") == \"ok\":\n",
    "                for article in appmsg_response.json().get(\"app_msg_list\"):\n",
    "                    article_link_url = article.get(\"link\")\n",
    "                    article_title = article.get(\"title\")\n",
    "                    article_time = article.get(\"update_time\")\n",
    "                    yield {\n",
    "                        \"article_link_url\" : article_link_url,\n",
    "                        \"article_title\" : article_title,\n",
    "                        \"article_time\" : article_time\n",
    "                    }\n",
    "                print(\"文章翻页中.....\")\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                time.sleep(4000)\n",
    "\n",
    "#获取文章的html代码\n",
    "def get_article_html(url):\n",
    "    try:\n",
    "        response = requests.get(url,headers=header)\n",
    "        if response.status_code == 200 :\n",
    "            return response.text\n",
    "        else:\n",
    "            return None\n",
    "    except RequestException:\n",
    "        return None\n",
    "\n",
    "#获取文章内容\n",
    "def parse_article_content(html):\n",
    "    doc = PyQuery(html)\n",
    "    content = doc(\".rich_media_content p\").text()\n",
    "    content = content.replace(\"\\r\\n\", \"\")\n",
    "    content = content.replace(\"\\n\", \"\")\n",
    "    return content\n",
    "\n",
    "\n",
    "#写入文件txt格式\n",
    "def save_to_file(content):\n",
    "    with open(\"wechat_official.txt\",\"a+\",encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(content, ensure_ascii=False) + \"\\n\")\n",
    "        f.close()\n",
    "\n",
    "\n",
    "#写入文件标题\n",
    "def write_title_file():\n",
    "    with open (\"wechat_official.csv\",\"a+\",encoding=\"utf-8-sig\",newline=\"\") as f:\n",
    "        wea_for=csv.writer(f,delimiter=\",\")\n",
    "        wea_for.writerow([\"微信名\",\"微信号\",\"标题\",\"时间\",\"内容\"])\n",
    "\n",
    "#写入文件内容\n",
    "def write_content_file(content):\n",
    "    with open (\"wechat_official.csv\",\"a+\",encoding=\"utf-8-sig\",newline=\"\") as f:\n",
    "        wea_for=csv.writer(f,delimiter=\",\")\n",
    "        wea_for.writerow([content[\"nickname\"],content[\"alias\"],content[\"title\"],content[\"date\"],content[\"content\"]])\n",
    "\n",
    "#主函数\n",
    "def main():\n",
    "    global data_count\n",
    "    open_wechat_official()   #获取cookies，一般不用每次都运行，每天运行一次\n",
    "    write_title_file()\n",
    "    cookies,token = get_token_and_cookie()\n",
    "    keyword = input(\"请输入要爬取的关键字:\")\n",
    "    for wechat_official in get_wechat_fakeid(cookies,token,keyword):\n",
    "        # print(wechat_official)\n",
    "        fakeid = wechat_official[\"fakeid\"]\n",
    "        nickname = wechat_official[\"nickname\"]\n",
    "        alias = wechat_official[\"alias\"]\n",
    "        for wechat_article in input_wechat_get_article(cookies,token,fakeid):\n",
    "            # print(wechat_article)\n",
    "            article_link_url = wechat_article[\"article_link_url\"]\n",
    "            article_title = wechat_article[\"article_title\"]\n",
    "            article_time = wechat_article[\"article_time\"]\n",
    "            date = time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime(article_time))\n",
    "            html = get_article_html(article_link_url)\n",
    "            if html :\n",
    "                content = parse_article_content(html)\n",
    "                crawl_content = {\n",
    "                    \"nickname\" : nickname, #微信名\n",
    "                    \"alias\" : alias,   #微信号\n",
    "                    \"title\" : article_title,\n",
    "                    \"date\" : date, #时间\n",
    "                    \"content\" : content #内容\n",
    "                }\n",
    "                write_content_file(crawl_content)\n",
    "                # save_to_file(crawl_content)\n",
    "                print(\"获取到第%d条数据\" % data_count)\n",
    "                data_count +=1\n",
    "                # print(crawl_content)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
